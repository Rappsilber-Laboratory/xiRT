LSTM:
  activation: tanh
  activity_regularization: l2
  activityregularizer_value: 0.001
  bidirectional: true
  kernel_regularization: l2
  kernelregularizer_value: 0.001
  lstm_bn: true
  nlayers: 1
  type: GRU
  units: 5
dense:
  activation:
  - relu
  - relu
  - relu
  dense_bn:
  - true
  - true
  - true
  dropout:
  - 0.1
  - 0.1
  - 0.1
  kernel_regularizer:
  - l2
  - l2
  - l2
  neurons:
  - 50
  - 25
  - 10
  nlayers: 3
  regularization:
  - true
  - true
  - true
  regularizer_value:
  - 0.001
  - 0.001
  - 0.001
embedding:
  length: 50
learning:
  batch_size: 512
  epochs: 1
  learningrate: 0.001
  verbose: 1
  optimizer: adam
output:
  scx-activation: sigmoid
  scx-column: scx_ordinal
  scx-dimension: 9
  scx-loss: binary_crossentropy
  scx-metrics: mse
  scx-weight: 50
siamese:
  use: True
  merge_type: add
  single_predictions: True
callbacks:
  check_point: True
  log_csv: True
  early_stopping: True
  early_stopping_patience: 15
  tensor_board: False
  progressbar: True
  reduce_lr: True
  reduce_lr_factor: 0.5
  reduce_lr_patience: 15
predictions:
  continues: []
  # simply write fractions: [] if no fraction prediction is desired
  fractions: [scx]
column_names:
  peptide1_sequence: "Peptide1"
  peptide2_sequence: "Peptide2"
  link_pos_basename: "LinkPos"
  peptide1_unmod_sequence: "Peptide1"
  peptide2_unmod_sequence: "Peptide2"
  score: "score"